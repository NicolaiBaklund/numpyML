{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77d4dcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch\n",
    "import pandas as pd\n",
    "from nn import model, optimizers, losses\n",
    "from nn.layers import Dense\n",
    "from nn.activations import Sigmoid, ReLU\n",
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, filepath):\n",
    "        df = pd.read_csv(filepath)\n",
    "        self.X = df[[\"x0\", \"x1\"]].values.astype(\"float32\")\n",
    "        self.y = df[\"y\"].values.astype(\"int\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.X[idx])\n",
    "        y = torch.tensor(self.y[idx])\n",
    "        return x, y\n",
    "    \n",
    "\n",
    "\n",
    "dataset = CSVDataset(\"../data/nn_data.csv\")\n",
    "\n",
    "random_generator = torch.Generator().manual_seed(42)\n",
    "\n",
    "train_data, test_data = random_split(dataset, [int(0.8*len(dataset)), int(0.2*len(dataset))], generator=random_generator)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, generator=random_generator)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe92c1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.Sequential([\n",
    "    Dense(2, 25),\n",
    "    ReLU(),\n",
    "    Dense(25, 10),\n",
    "    ReLU(),\n",
    "    Dense(10, 1),\n",
    "    Sigmoid()\n",
    "])\n",
    "\n",
    "loss_fn = losses.BinaryCrossEntropyWithLogits()\n",
    "optim = optimizers.SGD(model.parameters(), model.gradients(), learning_rate=0.01)\n",
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693fa061",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2, 25),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(25, 10),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(10, 1),\n",
    "    torch.nn.Sigmoid()\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba0d1fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 0.6296\n",
      "Epoch [20/1000], Loss: 0.4846\n",
      "Epoch [30/1000], Loss: 0.4745\n",
      "Epoch [40/1000], Loss: 0.2170\n",
      "Epoch [50/1000], Loss: 0.2958\n",
      "Epoch [60/1000], Loss: 0.2753\n",
      "Epoch [70/1000], Loss: 0.1944\n",
      "Epoch [80/1000], Loss: 0.4611\n",
      "Epoch [90/1000], Loss: 0.2148\n",
      "Epoch [100/1000], Loss: 0.6098\n",
      "Epoch [110/1000], Loss: 0.4390\n",
      "Epoch [120/1000], Loss: 0.2359\n",
      "Epoch [130/1000], Loss: 0.5900\n",
      "Epoch [140/1000], Loss: 0.4306\n",
      "Epoch [150/1000], Loss: 0.2569\n",
      "Epoch [160/1000], Loss: 0.3577\n",
      "Epoch [170/1000], Loss: 0.5810\n",
      "Epoch [180/1000], Loss: 0.3620\n",
      "Epoch [190/1000], Loss: 0.1694\n",
      "Epoch [200/1000], Loss: 0.2832\n",
      "Epoch [210/1000], Loss: 0.1442\n",
      "Epoch [220/1000], Loss: 0.1685\n",
      "Epoch [230/1000], Loss: 0.2404\n",
      "Epoch [240/1000], Loss: 0.4116\n",
      "Epoch [250/1000], Loss: 0.1591\n",
      "Epoch [260/1000], Loss: 0.4443\n",
      "Epoch [270/1000], Loss: 0.2425\n",
      "Epoch [280/1000], Loss: 0.1910\n",
      "Epoch [290/1000], Loss: 0.3989\n",
      "Epoch [300/1000], Loss: 0.3401\n",
      "Epoch [310/1000], Loss: 0.1803\n",
      "Epoch [320/1000], Loss: 0.2079\n",
      "Epoch [330/1000], Loss: 0.1876\n",
      "Epoch [340/1000], Loss: 0.1721\n",
      "Epoch [350/1000], Loss: 0.4984\n",
      "Epoch [360/1000], Loss: 0.2487\n",
      "Epoch [370/1000], Loss: 0.2813\n",
      "Epoch [380/1000], Loss: 0.1932\n",
      "Epoch [390/1000], Loss: 0.4107\n",
      "Epoch [400/1000], Loss: 0.3712\n",
      "Epoch [410/1000], Loss: 0.6124\n",
      "Epoch [420/1000], Loss: 0.3021\n",
      "Epoch [430/1000], Loss: 0.2858\n",
      "Epoch [440/1000], Loss: 0.3124\n",
      "Epoch [450/1000], Loss: 0.3849\n",
      "Epoch [460/1000], Loss: 0.3658\n",
      "Epoch [470/1000], Loss: 0.5746\n",
      "Epoch [480/1000], Loss: 0.2905\n",
      "Epoch [490/1000], Loss: 0.2587\n",
      "Epoch [500/1000], Loss: 0.2913\n",
      "Epoch [510/1000], Loss: 0.3643\n",
      "Epoch [520/1000], Loss: 0.3522\n",
      "Epoch [530/1000], Loss: 0.3957\n",
      "Epoch [540/1000], Loss: 0.1393\n",
      "Epoch [550/1000], Loss: 0.3722\n",
      "Epoch [560/1000], Loss: 0.1812\n",
      "Epoch [570/1000], Loss: 0.3158\n",
      "Epoch [580/1000], Loss: 0.1731\n",
      "Epoch [590/1000], Loss: 0.3422\n",
      "Epoch [600/1000], Loss: 0.1397\n",
      "Epoch [610/1000], Loss: 0.2243\n",
      "Epoch [620/1000], Loss: 0.1876\n",
      "Epoch [630/1000], Loss: 0.3954\n",
      "Epoch [640/1000], Loss: 0.2954\n",
      "Epoch [650/1000], Loss: 0.1293\n",
      "Epoch [660/1000], Loss: 0.3037\n",
      "Epoch [670/1000], Loss: 0.1031\n",
      "Epoch [680/1000], Loss: 0.1875\n",
      "Epoch [690/1000], Loss: 0.2320\n",
      "Epoch [700/1000], Loss: 0.2992\n",
      "Epoch [710/1000], Loss: 0.2116\n",
      "Epoch [720/1000], Loss: 0.1988\n",
      "Epoch [730/1000], Loss: 0.3268\n",
      "Epoch [740/1000], Loss: 0.1360\n",
      "Epoch [750/1000], Loss: 0.1651\n",
      "Epoch [760/1000], Loss: 0.3771\n",
      "Epoch [770/1000], Loss: 0.0904\n",
      "Epoch [780/1000], Loss: 0.1990\n",
      "Epoch [790/1000], Loss: 0.4718\n",
      "Epoch [800/1000], Loss: 0.2011\n",
      "Epoch [810/1000], Loss: 0.2720\n",
      "Epoch [820/1000], Loss: 0.2516\n",
      "Epoch [830/1000], Loss: 0.1548\n",
      "Epoch [840/1000], Loss: 0.3810\n",
      "Epoch [850/1000], Loss: 0.0756\n",
      "Epoch [860/1000], Loss: 0.2828\n",
      "Epoch [870/1000], Loss: 0.3833\n",
      "Epoch [880/1000], Loss: 0.2745\n",
      "Epoch [890/1000], Loss: 0.3290\n",
      "Epoch [900/1000], Loss: 0.2799\n",
      "Epoch [910/1000], Loss: 0.2634\n",
      "Epoch [920/1000], Loss: 0.2642\n",
      "Epoch [930/1000], Loss: 0.2187\n",
      "Epoch [940/1000], Loss: 0.2652\n",
      "Epoch [950/1000], Loss: 0.3494\n",
      "Epoch [960/1000], Loss: 0.1197\n",
      "Epoch [970/1000], Loss: 0.3137\n",
      "Epoch [980/1000], Loss: 0.0856\n",
      "Epoch [990/1000], Loss: 0.3298\n",
      "Epoch [1000/1000], Loss: 0.3787\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        \n",
    "\n",
    "        y_pred = model.forward(X_batch.numpy())\n",
    "        loss = loss_fn.forward(y_pred, y_batch.numpy())\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optim.zero_grad()\n",
    "        grad = loss_fn.backward()\n",
    "        model.backward(grad)\n",
    "        optim.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19c0bcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test data...\n",
      "7\n",
      "y_np.shape: (32,)\n",
      "pred.shape: (32, 1)\n",
      "y_np.shape: (32,)\n",
      "pred.shape: (32, 1)\n",
      "y_np.shape: (32,)\n",
      "pred.shape: (32, 1)\n",
      "y_np.shape: (32,)\n",
      "pred.shape: (32, 1)\n",
      "y_np.shape: (32,)\n",
      "pred.shape: (32, 1)\n",
      "y_np.shape: (32,)\n",
      "pred.shape: (32, 1)\n",
      "y_np.shape: (8,)\n",
      "pred.shape: (8, 1)\n",
      "Test Results:\n",
      "Correct: 188, Total: 200\n",
      "Accuracy: 0.9400\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "print(\"Evaluating on test data...\")\n",
    "print(len(test_loader))\n",
    "for x, y in test_loader:\n",
    "    x_np = x.numpy().astype(np.float32)\n",
    "    y_np = y.numpy()                  # shape (B,)\n",
    "\n",
    "    logits = model.forward(x_np, training=False)     # shape (B, C)\n",
    "    pred = (logits >= 0.5).astype(np.float32)                     # shape (B,)\n",
    "    correct += (pred.squeeze() == y_np).sum()                  # sum over batch -> scalar\n",
    "    total   += y_np.shape[0]  \n",
    "    print(\"y_np.shape:\", y_np.shape)   \n",
    "    print(\"pred.shape:\", pred.shape)\n",
    "acc = correct / total\n",
    "print(\"Test Results:\") \n",
    "print(f\"Correct: {correct}, Total: {total}\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
